{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C8XY66/GIN/blob/main/GIN_Log_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9crjFcNyO9lN"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6ERJo-3U1Uq"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMXW6FKbU23u"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/optuna/optuna.git\n",
        "!pip install optuna-dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh5Jy70SU4Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fe5e31-335d-4cf4-a7ca-20429ca9d785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "import pytz\n",
        "import numpy as np\n",
        "from typing import Optional\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data.lightning import LightningDataset\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GIN, MLP, global_add_pool\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from optuna.visualization.matplotlib import plot_contour, plot_edf, plot_intermediate_values, plot_optimization_history, plot_parallel_coordinate, plot_param_importances, plot_slice\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "MAIN_DIR = \"/content/gdrive/My Drive/ColabNotebooks/\" \n",
        "PARENT_DIR = None\n",
        "\n",
        "\n",
        "import logging\n",
        "#logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
        "#logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
        "#logging.getLogger(\"lightning\").setLevel(logging.CRITICAL)\n",
        "#logging.getLogger('lightning').setLevel(0)\n",
        "#logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"pytorch_lightning.callbacks.early_stopping\").setLevel(logging.WARNING)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atTqw8aphQQp",
        "outputId": "137d433d-0abd-4c02-f065-46c1ee919a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Check for CUDA system support and use GPU if available otherwise run on CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # device = Context-manager that changes the selected device\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTyVGyyJrGDW"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "DATASET_NAME = 'NCI1'\n",
        "num_layers = 5\n",
        "lr = 0.01 \n",
        "EPOCHS = 20 #final = 1000\n",
        "SEED = 42\n",
        "N_SPLITS = 3\n",
        "REP = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(pl.LightningModule):\n",
        "    def __init__(self, in_channels: int, out_channels: int,\n",
        "                 hidden_channels: int, dropout, num_layers=num_layers):\n",
        "        super().__init__()\n",
        "        self.gnn = GIN(in_channels, hidden_channels, num_layers,\n",
        "                       dropout=dropout, jk='cat')\n",
        "\n",
        "        self.classifier = MLP([hidden_channels, hidden_channels, out_channels],\n",
        "                              norm=\"batch_norm\", dropout=dropout)\n",
        "\n",
        "        self.train_acc = Accuracy(task='multiclass', num_classes=out_channels)\n",
        "        self.val_acc = Accuracy(task='multiclass', num_classes=out_channels)\n",
        "        self.test_acc = Accuracy(task='multiclass', num_classes=out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.gnn(x, edge_index)\n",
        "        x = global_add_pool(x, batch)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, data, batch_idx):\n",
        "        y_hat = self(data.x, data.edge_index, data.batch)\n",
        "        loss = F.cross_entropy(y_hat, data.y)\n",
        "        self.train_acc(y_hat.softmax(dim=-1), data.y)\n",
        "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('train_acc', self.train_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, data, batch_idx):\n",
        "        y_hat = self(data.x, data.edge_index, data.batch)\n",
        "        loss = F.cross_entropy(y_hat, data.y)\n",
        "        self.val_acc(y_hat.softmax(dim=-1), data.y)\n",
        "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('val_acc', self.val_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "\n",
        "    def test_step(self, data, batch_idx):\n",
        "        y_hat = self(data.x, data.edge_index, data.batch)\n",
        "        loss = F.cross_entropy(y_hat, data.y)\n",
        "        self.test_acc(y_hat.softmax(dim=-1), data.y)\n",
        "        self.log('test_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('test_acc', self.test_acc, prog_bar=True, on_step=False,on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "c_Fs7_0mC0og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKE31eyglQ9p"
      },
      "outputs": [],
      "source": [
        "class GraphDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, dataset_name, n_splits=10, fold=0):\n",
        "        super().__init__()\n",
        "        self.dataset_name = dataset_name\n",
        "        self.n_splits = n_splits\n",
        "        self.fold = fold\n",
        "\n",
        "    def prepare_data(self):    \n",
        "        self.dataset = TUDataset(root='data/TUDataset', name=self.dataset_name)\n",
        "        self.dataset = self.dataset[:1000] #for quick experiments\n",
        "        self.skf = StratifiedKFold(n_splits=self.n_splits)\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None, fold: int = 0, batch_size: int = 32):\n",
        "        self.fold = fold\n",
        "        self.batch_size = batch_size\n",
        "        y = [data.y.item() for data in self.dataset]\n",
        "\n",
        "        train_indices, test_indices = list(self.skf.split(torch.zeros(len(y)), y))[self.fold]\n",
        "        train_dataset = self.dataset[train_indices]\n",
        "        \n",
        "        num_val = int(len(train_dataset) * 0.1)\n",
        "        num_train = len(train_dataset) - num_val\n",
        "        \n",
        "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(train_dataset, [num_train, num_val])\n",
        "        self.test_dataset = self.dataset[test_indices]\n",
        "      \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    @property\n",
        "    def num_node_features(self):\n",
        "        return self.dataset.num_node_features\n",
        "\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return self.dataset.num_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_log_dir(repetition_index, fold_index, extra_info=''):\n",
        "    global PARENT_DIR\n",
        "    \n",
        "    # Current timestamp\n",
        "    now = datetime.datetime.now(pytz.timezone('Europe/Zurich')).strftime(\"%Y-%m-%d_%H-%M\")\n",
        "\n",
        "    # Parent directory\n",
        "    parent_dir_info = f\"{DATASET_NAME}_reps_{REP}_folds_{N_SPLITS}_epochs_{EPOCHS}\"\n",
        "\n",
        "    if PARENT_DIR is None:\n",
        "        PARENT_DIR = f\"{MAIN_DIR}logs/{parent_dir_info}_{now}\"\n",
        "        if not os.path.exists(PARENT_DIR):\n",
        "            os.makedirs(PARENT_DIR)\n",
        "\n",
        "    # Subdirectory for the specific repetition and fold\n",
        "    if repetition_index is not None and fold_index is not None:\n",
        "        sub_dir = f\"{PARENT_DIR}/rep_{repetition_index}_fold_{fold_index}{extra_info}\"\n",
        "        if not os.path.exists(sub_dir):\n",
        "            os.makedirs(sub_dir)\n",
        "    else:\n",
        "        sub_dir = PARENT_DIR\n",
        "    \n",
        "    return sub_dir"
      ],
      "metadata": {
        "id": "po9ze2H0yJmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trainer(log_dir, epochs, pruning_callback=None):\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=10, verbose=True)\n",
        "  \n",
        "    callbacks = [early_stopping]\n",
        "    if pruning_callback is not None:\n",
        "        callbacks.append(pruning_callback)\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = pl.Trainer(\n",
        "        callbacks=callbacks,\n",
        "        max_epochs=epochs,\n",
        "        log_every_n_steps=5,\n",
        "        logger=TensorBoardLogger(save_dir=log_dir),\n",
        "        enable_progress_bar=False,\n",
        "        enable_model_summary=False,\n",
        "    )\n",
        "\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "8h1J2xdqMzV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmWBXCATF5VS"
      },
      "outputs": [],
      "source": [
        "def objective(trial, datamodule, epochs, repetition_index, fold_index): \n",
        "\n",
        "    # Optimise hyperparameters\n",
        "    hidden_channels = trial.suggest_categorical('hidden_channels', [16, 32])\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 128])\n",
        "    dropout = trial.suggest_categorical('dropout', [0.0, 0.5])\n",
        "\n",
        "    # Model and DataModule\n",
        "    datamodule.setup(fold=0, batch_size=batch_size)\n",
        "    model = GNNModel(in_channels=datamodule.num_node_features, out_channels=datamodule.num_classes, hidden_channels=hidden_channels, dropout=dropout)\n",
        "\n",
        "    # Training\n",
        "    pruning_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_acc\") #from optuna-pl-integration\n",
        "    \n",
        "    log_dir = create_log_dir(repetition_index, fold_index, extra_info='_selection')\n",
        "    trainer = create_trainer(log_dir, epochs=epochs, pruning_callback=pruning_callback)\n",
        "    \n",
        "    hyperparameters = dict(hidden_channels=hidden_channels, batch_size=batch_size, epochs=epochs, dropout=dropout)\n",
        "    trainer.logger.log_hyperparams(hyperparameters)    \n",
        "    \n",
        "    trainer.fit(model, datamodule=datamodule)\n",
        "\n",
        "    return trainer.callback_metrics['val_acc'].item()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhW7-XpMDGLv"
      },
      "outputs": [],
      "source": [
        "def retrain_and_evaluate(model, datamodule, epochs, repetition_index, fold_index):\n",
        "    \n",
        "    log_dir = create_log_dir(repetition_index, fold_index, extra_info='_assessment')\n",
        "    trainer = create_trainer(log_dir, epochs=epochs, pruning_callback=None)\n",
        "    \n",
        "    trainer.fit(model, datamodule=datamodule)\n",
        "    trainer.test(model, datamodule=datamodule)\n",
        "\n",
        "    return trainer.callback_metrics['test_acc'].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jZzCJL2nLkQG",
        "outputId": "ee759b35-59fb-4a9b-d8ee-6caedd4d511b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/NCI1.zip\n",
            "Extracting data/TUDataset/NCI1/NCI1.zip\n",
            "Processing...\n",
            "Done!\n",
            "[I 2023-04-19 17:03:03,245] A new study created in memory with name: no-name-3e54b8d3-47d1-4ab3-9252-c191fd4decc6\n",
            "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "  warning_cache.warn(\n",
            "[I 2023-04-19 17:03:20,292] Trial 0 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 32, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:24,764] Trial 1 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:28,188] Trial 2 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:31,615] Trial 3 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:36,009] Trial 4 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:40,033] Trial 5 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:43,497] Trial 6 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:46,955] Trial 7 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/gdrive/My Drive/ColabNotebooks/logs/NCI1_reps_2_folds_3_epochs_20_2023-04-19_19-03/rep_0_fold_0_assessment/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial for fold 0: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0002490418264642358  \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0002490418264642358   </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-04-19 17:03:51,514] A new study created in memory with name: no-name-1f46eceb-0457-4ef3-85cb-e054747edafc\n",
            "[I 2023-04-19 17:03:55,224] Trial 0 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 32, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:03:58,626] Trial 1 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:02,026] Trial 2 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:06,744] Trial 3 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:10,074] Trial 4 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:13,443] Trial 5 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:16,939] Trial 6 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:21,750] Trial 7 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/gdrive/My Drive/ColabNotebooks/logs/NCI1_reps_2_folds_3_epochs_20_2023-04-19_19-03/rep_0_fold_1_assessment/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial for fold 1: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0005033960333094001  \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0005033960333094001   </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-04-19 17:04:25,718] A new study created in memory with name: no-name-23dc2762-86c8-4b89-b02b-789492af87e1\n",
            "[I 2023-04-19 17:04:29,479] Trial 0 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 32, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:34,204] Trial 1 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:38,194] Trial 2 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:41,653] Trial 3 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:45,044] Trial 4 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:49,720] Trial 5 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:53,427] Trial 6 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:04:56,914] Trial 7 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/gdrive/My Drive/ColabNotebooks/logs/NCI1_reps_2_folds_3_epochs_20_2023-04-19_19-03/rep_0_fold_2_assessment/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial for fold 2: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0002285700902575627  \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0002285700902575627   </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-04-19 17:05:00,563] A new study created in memory with name: no-name-32fdd9f1-8cd1-4d70-bc6a-cea5a44860e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance for repetition 0: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-04-19 17:05:06,011] Trial 0 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 32, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:09,495] Trial 1 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:13,280] Trial 2 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:17,424] Trial 3 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:21,646] Trial 4 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:25,032] Trial 5 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:28,480] Trial 6 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:32,886] Trial 7 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/gdrive/My Drive/ColabNotebooks/logs/NCI1_reps_2_folds_3_epochs_20_2023-04-19_19-03/rep_1_fold_0_assessment/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial for fold 0: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.000134011497721076   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.000134011497721076    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-04-19 17:05:36,764] A new study created in memory with name: no-name-9a6b3afd-de63-4bc0-8b5d-195c2a07bdba\n",
            "[I 2023-04-19 17:05:40,133] Trial 0 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 32, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:43,584] Trial 1 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:48,327] Trial 2 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:51,839] Trial 3 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:55,267] Trial 4 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:05:58,658] Trial 5 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:03,314] Trial 6 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:07,131] Trial 7 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/gdrive/My Drive/ColabNotebooks/logs/NCI1_reps_2_folds_3_epochs_20_2023-04-19_19-03/rep_1_fold_1_assessment/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial for fold 1: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  6.391129863914102e-05  \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   6.391129863914102e-05   </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-04-19 17:06:10,650] A new study created in memory with name: no-name-1767c93d-9c48-4a62-9e19-912ead10e1f5\n",
            "[I 2023-04-19 17:06:14,680] Trial 0 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 32, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:18,986] Trial 1 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:22,396] Trial 2 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:25,805] Trial 3 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:30,034] Trial 4 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:33,896] Trial 5 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 128, 'dropout': 0.0}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:37,325] Trial 6 finished with value: 1.0 and parameters: {'hidden_channels': 16, 'batch_size': 32, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "[I 2023-04-19 17:06:40,746] Trial 7 finished with value: 1.0 and parameters: {'hidden_channels': 32, 'batch_size': 128, 'dropout': 0.5}. Best is trial 0 with value: 1.0.\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/gdrive/My Drive/ColabNotebooks/logs/NCI1_reps_2_folds_3_epochs_20_2023-04-19_19-03/rep_1_fold_2_assessment/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial for fold 2: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m 0.00020151649368926883  \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">  0.00020151649368926883   </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average performance for repetition 1: 1.0\n",
            "Overall average performance: 1.0\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__': \n",
        "\n",
        "    datamodule = GraphDataModule(dataset_name=DATASET_NAME)\n",
        "  \n",
        "    overall_performances = []\n",
        "    for r in range(REP):\n",
        "        datamodule.prepare_data()\n",
        "        fold_performances = []\n",
        "        for fold in range(N_SPLITS):\n",
        "            # Create a new study object for each fold\n",
        "            study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner(), sampler=optuna.samplers.TPESampler(seed=SEED),)\n",
        "            datamodule.setup(\"fit\", fold)\n",
        "            study.optimize(lambda trial: objective(trial, datamodule, EPOCHS, r, fold), n_trials=8)\n",
        "            print(f\"Best trial for fold {fold}: {study.best_trial.value}\")\n",
        "\n",
        "            # Retrain the model with the best hyperparameters\n",
        "            best_params = study.best_trial.params\n",
        "            model = GNNModel(in_channels=datamodule.num_node_features,\n",
        "                          out_channels=datamodule.num_classes,\n",
        "                          hidden_channels=best_params['hidden_channels'],\n",
        "                          dropout=best_params['dropout'])\n",
        "            datamodule.setup(\"fit\", fold, batch_size=best_params['batch_size'])\n",
        "            test_acc = retrain_and_evaluate(model, datamodule, EPOCHS, r, fold)\n",
        "            fold_performances.append(test_acc)\n",
        "\n",
        "        avg_performance = np.mean(fold_performances)\n",
        "        print(f\"Average performance for repetition {r}: {avg_performance}\")\n",
        "        overall_performances.append(avg_performance)\n",
        "\n",
        "    print(f\"Overall average performance: {np.mean(overall_performances)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir '/content/gdrive/My Drive/ColabNotebooks/'\n",
        "%tensorboard --logdir '{MAIN_DIR}'"
      ],
      "metadata": {
        "id": "t86u3fkaDp42"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmc+qtKZ3tlLpMsORhurdG",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}